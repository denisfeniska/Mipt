{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e796a4d-2ebe-4de5-9fce-246075ef8f64",
   "metadata": {},
   "source": [
    "# Выбор модели. Валидация. Настройка гиперпараметров.\n",
    "\n",
    "Уже научились читать и чистить данные. Познакомились с некоторыми моделями машинного обучения, а также метриками для задач классификации и регрессии.\n",
    "\n",
    "**Но как понять, что мы не переобучились? Достаточной ли обобщающей способностью обладает модель? На сколько хорош выбранный _пайплайн_ в целом?**\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/overfitting.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "Проблема выбора:\n",
    "- модели алгоритмов\n",
    "- гиперпараметров\n",
    "- способа предобработки данных\n",
    "\n",
    "\n",
    "**Валидация** - процедура эмпирического оценивания обобщающей способности модели, которая используется для сравнения между собой различных моделей и выбора наилучшей для конкретной задачи.\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6963ce7-8db8-491f-8f3d-784f8209268c",
   "metadata": {},
   "source": [
    "## [Разбиение данных](https://education.yandex.ru/handbook/ml/article/kross-validaciya)\n",
    "\n",
    "### Общая схема разбиения данных: Train / Validation / Test Set\n",
    "\n",
    "- **Обучающая выборка** - Training set (70%)\n",
    "  - обучение модели (настойка ее параметров / весов)\n",
    "- **Валидационная выборка** - Validation set (15%)\n",
    "  - выбор пайплайна (модели / гиперпараметров / способа обработки данных)\n",
    "  - иногда: локальный контроль\n",
    "- **Тестовая выборка** - Test set (15%)\n",
    "  - оценка качества алгоритма\n",
    "  - иногда: итоговая оценка алгоритма\n",
    "  - _лучше выбрать в самом начале и вспомнить только на финальном этапе_\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/data_split.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "**Оптимизация качества моделей и их сравнение на одном и том же множестве, может неявно заложить в модели информацию о тестовом множестве, что может привести к получению результатов хуже ожидаемых на новых данных.**\n",
    "\n",
    "Реализация разбиения в [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "```\n",
    "\n",
    "sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "\n",
    "```\n",
    "- ``train_size/test_size: Optional[Union[int, float]]`` - $100: 70/30 \\rightarrow 30: 50/50$ - для начального приближения; здравый смысл далее;\n",
    "  - большее обучение:\n",
    "    - более репрезентативная обучающая выборка\n",
    "  - больший контроль:\n",
    "    - более надежная оценка качества\n",
    "- ``random_state`` - воспроизводимость результатов\n",
    "- ``shuffle: bool`` - перемешивание сэмплов.\n",
    "  - Важно смотреть на природу данных!\n",
    "- ``stratify`` - _(стратификация)_ разбиение на трейн и тест, сохраняющее соотношение классов, представленное в исходном датасете.\n",
    "  - Важно с случае сильно несбалансированных данных!\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/general-population.svg\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "Для обучения и выбора модели есть много вариантов разбиения:\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f3c4e-b213-4782-8cd6-4dc148346dd7",
   "metadata": {},
   "source": [
    "### [Кросс-Валидация](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "Зачастую, когда говорят о кросс-валидации имеют в виду именно  метод [K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "\n",
    "Он устроен следующим образом:\n",
    "\n",
    "- Фиксируем целое число K (обычно от 5 до 10 и нечетное)\n",
    "- Делим выборку на K примерно равных частей (фолдов)\n",
    "- Цикл по i = 1...K:\n",
    "  - Использовать i-ую часть для валидации, объединение остальных - для обучения.\n",
    "- Финальный скор модели получается либо усреднением K получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/CV.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "В scikit-learn реализовано несколько дополнительных методов:\n",
    "  - [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) - в отличие от K-Fold принимает на вход не только данные, но и модель, и прочие параметры.\n",
    "    - на выходе оценивает ее качество, а не возвращает разбиение данных.\n",
    "  - [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) - это метод K-Fold, использующий стратификацию при разбиении на фолды: каждый фолд содержит примерно такое же соотношение классов, как и всё исходное множество.\n",
    "    - Такой подход может потребоваться в случае, например, очень несбалансированного соотношения классов, когда при обычном random split некоторые фолды могут либо вообще не содержать семплов каких-то классов, либо содержать их слишком мало.\n",
    "   \n",
    "### [Leave-One-Out / LOO](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html)\n",
    "\n",
    "- Вырождение K-Fold при K соответсвующем размеру выборки (каждый фолд состоит ровно из одного сэмлпа).\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/LOOCV.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "- Большие k:\n",
    "  + (+) надёжнее оценка качества\n",
    "  + (+) обучающая выборка больше походит на все данные\n",
    "  - (-) вычислительно затратно\n",
    "    - обычно применяют\n",
    "      -  когда данных достаточно мало\n",
    "      -  при наличии большого количества вычислительных ресурсов, позволяющих проводить все K итераций параллельно.\n",
    "  - (-) не любое качество адекватно оценивается на маленьких подвыборках\n",
    "\n",
    "### [Бутстреп (Bootstrap)](https://v-marco.github.io/psmo_book/content/bootstrap/seminar.html)\n",
    "\n",
    "-  это псевдовыборка с возвращением, формируется как подвыборка полного объёма, на которой производится обучение модели, а на остальных объектах (которые не попали в обучение) – контроль.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/bootstrap.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "\n",
    "В контроль попадает:\n",
    "\n",
    "$$ \\left ( 1 - \\frac{1}{m} \\right )^m \\approx e^{-1} \\approx 0.37$$\n",
    "\n",
    "- Модель учится на выборке того же объема, что и итоговая\n",
    "- Похожа на исходную с точки зрения распределенения\n",
    "- Имеются дубликаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493084c9-064d-4af0-8d5d-77d88d9598a6",
   "metadata": {},
   "source": [
    "### Контроль по времени. [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)\n",
    "\n",
    "Контроль качества в задаче прогнозирования временных рядов имеет существенную особенность - данные не должны пересекаться по времени: тренировочные данные должны идти до валидационных, а валидационные — до тестовых. С учётом этих особенностей фолды в кросс-валидации для временных рядов располагаются вдоль временной оси так, как показано на следующей картинке:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/time_series.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "#### FYI: [Больше разбиений](https://scikit-learn.org/stable/api/sklearn.model_selection.html)\n",
    "\n",
    "\n",
    "#### На что обратить внимание?\n",
    "\n",
    "- высокое качество на обучении и низкое на контроле - overfitting\n",
    "  - сложность модели, шум, нерепрезентативность\n",
    "- низкое качество на обучении и контроле -  underfitting\n",
    "- нужно ли перемешивать данные? перемешали ли вы их?\n",
    "- не подглядываете в тест в процессе обработки/обучения/подбора гиперпараметров?\n",
    "- временные ряды\n",
    "\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b03270-5f87-4712-8261-279b70ad5792",
   "metadata": {},
   "source": [
    "## Гиперпараметры\n",
    "\n",
    "Чем гиперпараметры отличаются от параметров модели?\n",
    "  - Параметры модели настраиваются в процессе обучения модели на данных\n",
    "  - Гиперпараметры - характеристики модели, которые фиксируются до начала обучения модели (экспертно или переборно)\n",
    "\n",
    "Простейшие примеры гиперпараметров:\n",
    " - параметр регуляризации\n",
    " - темп обучения градиентного спуска (learning rate)\n",
    "\n",
    "\n",
    "### Простейшие стратегии подбора гиперпараметров. Переборные методы.\n",
    "\n",
    "#### Поиск по сетке. [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "Самым наивным способом поиска оптимального набора гиперпараметров является поиск по сетке. Метод выполняет полный перебор по изначально заданному подмножеству гиперпараметров выбранного алгоритма. Так как пространство поиска гиперпараметров выбранной модели машинного обучения может быть непрерывным и неограниченным, ML-разработчик сам должен установить границы и провести дискретизацию значений. Качество алгоритма поиска обычно определяется с помощью перекрестной проверки или отложенного набора данных. В результате своей работы алгоритм **поиска по сетке** выдаёт модель с гиперпараметрами, на которых был достигнут наилучший результат в процессе проверки.\n",
    "\n",
    "Основным недостатком данного метода является *проклятие размерности* -- проблема экспоненциального роста необходимых экспериментальных данных в зависимости от роста размерности пространства. Однако обычно метод довольно легко поддается распараллеливанию, так как зачастую гиперпараметры не зависят друг от друга.  \n",
    "\n",
    "\n",
    "#### Случайный поиск. [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "Основной идей случайного поиска является независимое сэмлирование из заранее определенного подмножества гиперпараметров до тех пор, пока не будет исчерпан заранее определенный бюджет, например, максимальное количество итераций. В отличие от предыдущего метода от разработчика не требуется проводить дискретизацию непрерывных значений, нужно лишь ограничить пространство поиска. Так же, как и  *поиск по сетке*, *случайный поиск* поддерживает параллельную работу, так как вычисления могут выполняться независимо, а также позволяет использовать априорные знания об оптимизируемых параметрах путем указания распределения на них. *Случайный поиск* превосходит *поиск по сетке* в случае, если на качество модели оказывает влияние лишь малое количество параметров.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/grid_vs_random_search.png\" width=\"650px\">,\n",
    "</div>\n",
    "\n",
    "График функция $g(x)$ изображен зеленым цветом сверху квадрата, а график функции $h(y)$ представлен на левой боковой части квадрата. В случае использования поиска по сетке, из $9$ измерений только $3$  протестируют функцию $g(x)$ в разных точках. При использовании случайного поиска все $9$ измерений эффективно исследуют $g(x)$ в $9$ разных точках. Такое поведение метода *поиска по сетке* в сравнении с методом *случайного поиска* является скорее правилом, чем исключением, в многомерной гиперпараметрической оптимизации.\n",
    "\n",
    "[**Примеры использования.**](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization)\n",
    "\n",
    "**Другие библиотеки**: [Optuna](https://optuna.org/), [scikit-optimize](https://scikit-optimize.github.io/stable/index.html), [hyperopt](http://hyperopt.github.io/hyperopt/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a059c185-20af-46ed-9ab5-05172db961b7",
   "metadata": {},
   "source": [
    "### Байесовская оптимизация\n",
    "\n",
    "Поиск по сетке и случайный поиск не используют информацию, полученную на основе предыдущих наблюдений. Байесовская оптимизация призвана устранить этот существенный недостаток. Концептуально имеется две области для выбора новых точек: рассмотрение точек в малоисследованных на текущий момент областях (_exploration_ стратегия) и рассмотрение точек в достаточно изученных областях, где с высокой вероятностью может находится оптимум (_exploitation_ стратегия). Для этого модель байесовской оптимизации использует 2 основных компонента:\n",
    "\n",
    "  - ***Вероятностная модель*** исследуемой функции. Она приближает распределение значений целевой функции на основе имеющихся данных (часто используют гауссовские процессы).\n",
    "  - ***Acquisition функция***, которая на основе некоторой статистической информации, полученной из вероятностной модели функции, определяет, в какой точке вычислять значение целевой функции на следующем шаге. Она балансирует между обозначенными стратегиями:\n",
    "    - исследует точки с большой дисперсией вероятностной модели функции\n",
    "    - исследует точки с большим средним вероятностной модели функции\n",
    "\n",
    "Один из примеров Acquisition функции - **Upper confidence bound (UCB)**:\n",
    "$$UCB[\\mathbf{x}] = \\mu(\\mathbf{x}) + \\beta^{1/2} \\sigma(\\mathbf{x}),$$\n",
    "где $\\mathbf{x}$ - вектор значений гиперпараметров, $\\mu(\\cdot)$ и $\\sigma(\\cdot)$ - среднее и стандартное отклонение вероятностой модели, а $\\beta$ - положительный параметр, который позволяет балансировать между _exploration_ и _exploitation_ стратегиями.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/bayes.png\" width=\"650px\">,\n",
    "</div>\n",
    "\n",
    "Основной проблемой байесовской оптимизации является отсутствие возможности распараллеливания процесса, так как вычисление каждой новой точки использует информацию о точках, полученных на предыдущих итерациях.\n",
    "\n",
    "[Successive Halving](https://arxiv.org/pdf/1502.07943), [HyperBand](https://arxiv.org/pdf/1603.06560), [BOHB](https://arxiv.org/pdf/1807.01774) и [обзор](https://habr.com/ru/companies/skillfactory/articles/528240/).\n",
    "\n",
    "### Эвристические алгоритмы.\n",
    "\n",
    "Эвристика - алгоритм решения задачи, включающий практический метод, не являющийся гарантированно точным или оптимальным, но достаточный для решения поставленной задачи.\n",
    "\n",
    "- Эвристический алгоритм, в отличие от точного, обладает следующими характерными особенностями:\n",
    "  - При использовании алгоритма результат не всегда будет гарантированно точным;\n",
    "  - В некоторых случаях алгоритм может привести к неверному результату;\n",
    "  - Возможен «пропуск цели», то есть решение не будет найдено, даже если известно, что оно заведомо существует;\n",
    "  - В ряде случаев может быть даже доказано, что эвристический алгоритм формально неверен. Но, несмотря на это, приемлем, если он дает неверный результат только в отдельных случаях, или же дает не абсолютно точный, но все же приемлемый результат.\n",
    "\n",
    "\n",
    "Примеры: \n",
    "- [Генетический алгоритм](https://ru.wikipedia.org/wiki/%D0%93%D0%B5%D0%BD%D0%B5%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC)\n",
    "- [Эволюционная стратегия](https://ru.wikipedia.org/wiki/%D0%AD%D0%B2%D0%BE%D0%BB%D1%8E%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D1%82%D0%B5%D0%B3%D0%B8%D1%8F)\n",
    "- [Дифференциальная эволюция](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%84%D1%84%D0%B5%D1%80%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%8D%D0%B2%D0%BE%D0%BB%D1%8E%D1%86%D0%B8%D1%8F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43807416-965d-4bc0-9e4a-d34d040b0efb",
   "metadata": {},
   "source": [
    "### Ссылки.\n",
    "- [Кросс-валидация handbook](https://education.yandex.ru/handbook/ml/article/kross-validaciya)\n",
    "- [Кросс-валидация nerc](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9A%D1%80%D0%BE%D1%81%D1%81-%D0%B2%D0%B0%D0%BB%D0%B8%D0%B4%D0%B0%D1%86%D0%B8%D1%8F)\n",
    "- [Лекция: Контроль качества и выбор модели. Дьяконов А.Г.](https://github.com/Dyakonov/MSUML/blob/main/2021autumn/ML040_control_202110a_______.pdf)\n",
    "- [Видео лекции: Контроль качества и выбор модели. Дьяконов А.Г.](https://www.youtube.com/watch?v=Q2jJ8_oU3-s&list=PLhe7c-LCgl4Ic-FRawaaEhUmDCQmGMtzx&index=7)\n",
    "- [Cross-Validation in Machine Learning: How to Do It Right](https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right)\n",
    "- [Подбор гиперпараметров](https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov)\n",
    "- [Optuna: подбор гиперпараметров для вашей модели](https://practicum.yandex.ru/blog/optuna-podbor-giperparametrov/)\n",
    "- [HyperBand и BOHB. Понимание современных алгоритмов оптимизации гиперпараметров](https://habr.com/ru/companies/skillfactory/articles/528240/)\n",
    "- [Hyperparameter optimization for Neural Networks](http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb49e7-a044-4a57-aa85-43fb7f1eff98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
